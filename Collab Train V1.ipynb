{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")  # Path to your YAML file\n",
        "results_dir = os.path.join(drive_base_path, \"results\")     # Directory to save results\n",
        "os.makedirs(results_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PFm9AcKqe8Y",
        "outputId": "04dc8092-c01e-45c0-c95b-cc3675615fff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrLsJUPjoy36",
        "outputId": "3943c2c4-64b4-413e-ed70-cc0bb1f41a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.52-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.52-py3-none-any.whl (901 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.52 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")\n",
        "results_dir = os.path.join(drive_base_path, \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "'''\n",
        "# Models to train and evaluate\n",
        "models = {\n",
        "    \"YOLOv3\": \"yolov3.pt\",\n",
        "    \"YOLOv4\": \"yolov4.pt\",\n",
        "    \"YOLOv5x\": \"yolov5x.pt\",\n",
        "    \"YOLOv6\": \"yolov6.pt\",\n",
        "    \"YOLOv7\": \"yolov7.pt\",\n",
        "}\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IloKysuTpqwA",
        "outputId": "f6c6f167-13ef-4699-a748-af02ba97d6c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Models to train and evaluate\\nmodels = {\\n    \"YOLOv3\": \"yolov3.pt\",\\n    \"YOLOv4\": \"yolov4.pt\",\\n    \"YOLOv5x\": \"yolov5x.pt\",\\n    \"YOLOv6\": \"yolov6.pt\",\\n    \"YOLOv7\": \"yolov7.pt\",\\n}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov3\n"
      ],
      "metadata": {
        "id": "GFUjvfog0hNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv3\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov3.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=12,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=640,\n",
        "    batch=8,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dir, model_name)\n",
        ")\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
        "    \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
        "    \"Precision\": val_results[\"metrics/precision\"],\n",
        "    \"Recall\": val_results[\"metrics/recall\"],\n",
        "    \"F1-Score\": val_results[\"metrics/F1\"],\n",
        "    \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
        "    \"Loss\": val_results[\"metrics/loss\"],\n",
        "    \"Speed\": val_results[\"metrics/speed\"],\n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save validation plots\n",
        "model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
        "\n",
        "print(f\"Results saved to {os.path.join(results_dir, model_name)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQw6mwFrCJo",
        "outputId": "ba9bdcb7-550e-4215-e374-f7dc849d98de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluating YOLOv3...\n",
            "PRO TIP 💡 Replace 'model=yolov3.pt' with new 'model=yolov3u.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Ultralytics 8.3.52 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov3.pt, data=/content/drive/My Drive/UAS Machine Learning/dataset.yaml, epochs=12, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=YOLOv3_detection2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/YOLOv3_detection2\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 1]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     37056  ultralytics.nn.modules.block.Bottleneck      [64, 64]                      \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    295680  ultralytics.nn.modules.block.Bottleneck      [128, 128]                    \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  8   4724736  ultralytics.nn.modules.block.Bottleneck      [256, 256]                    \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  8  18886656  ultralytics.nn.modules.block.Bottleneck      [512, 512]                    \n",
            "  9                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
            " 10                  -1  4  37761024  ultralytics.nn.modules.block.Bottleneck      [1024, 1024]                  \n",
            " 11                  -1  1   9440256  ultralytics.nn.modules.block.Bottleneck      [1024, 1024, False]           \n",
            " 12                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 13                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 14                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 15                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 16                  -2  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 18             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   2950656  ultralytics.nn.modules.block.Bottleneck      [768, 512, False]             \n",
            " 20                  -1  1   2360832  ultralytics.nn.modules.block.Bottleneck      [512, 512, False]             \n",
            " 21                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 22                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
            " 23                  -2  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 25             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 26                  -1  1    738048  ultralytics.nn.modules.block.Bottleneck      [384, 256, False]             \n",
            " 27                  -1  2   1181184  ultralytics.nn.modules.block.Bottleneck      [256, 256, False]             \n",
            " 28        [27, 22, 15]  1   7060444  ultralytics.nn.modules.head.Detect           [4, [256, 512, 1024]]         \n",
            "YOLOv3 summary: 310 layers, 103,695,548 parameters, 103,695,532 gradients, 283.0 GFLOPs\n",
            "\n",
            "Transferred 511/517 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/YOLOv3_detection2', view at http://localhost:6006/\n",
            "Freezing layer 'model.28.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/train/labels... 301 images, 0 backgrounds, 0 corrupt: 100%|██████████| 301/301 [02:04<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/My Drive/UAS Machine Learning/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels... 108 images, 0 backgrounds, 0 corrupt: 100%|██████████| 108/108 [00:43<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/My Drive/UAS Machine Learning/val/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/YOLOv3_detection2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 84 weight(decay=0.0), 91 weight(decay=0.0005), 90 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/YOLOv3_detection2\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/12      10.4G      1.969      2.542      2.101         48        640: 100%|██████████| 38/38 [00:26<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597   8.06e-05    0.00701    4.2e-05   1.39e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/12      10.2G      2.045      2.314       2.13         31        640: 100%|██████████| 38/38 [00:24<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597     0.0696      0.353     0.0936     0.0303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/12      10.3G      2.212      2.591      2.351         31        640: 100%|██████████| 38/38 [00:25<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597       0.47      0.246      0.138     0.0479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/12      10.3G      2.211      2.734      2.329         15        640: 100%|██████████| 38/38 [00:24<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.493      0.237      0.197       0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/12      10.4G      2.164       2.41      2.322         22        640: 100%|██████████| 38/38 [00:24<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597       0.61       0.34      0.309      0.126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/12      10.1G      2.101      2.222      2.288         22        640: 100%|██████████| 38/38 [00:24<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.394      0.338      0.281      0.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/12      10.1G      2.031      2.103      2.201         26        640: 100%|██████████| 38/38 [00:24<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.679      0.387       0.38      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/12      10.3G      1.987      2.001      2.159         27        640: 100%|██████████| 38/38 [00:24<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.648      0.417      0.415      0.185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/12      10.3G      1.953      1.866      2.127         20        640: 100%|██████████| 38/38 [00:24<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.773      0.442      0.508       0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the metrics\n",
        "print(\"\\nFinal Metrics:\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric, value in model_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "tlFkkzRNrFzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phulBRhVzpXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov4\n"
      ],
      "metadata": {
        "id": "WQ_YlN2m01I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv4\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov4.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=12,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=640,\n",
        "    batch=8,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dir, model_name)\n",
        ")\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
        "    \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
        "    \"Precision\": val_results[\"metrics/precision\"],\n",
        "    \"Recall\": val_results[\"metrics/recall\"],\n",
        "    \"F1-Score\": val_results[\"metrics/F1\"],\n",
        "    \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
        "    \"Loss\": val_results[\"metrics/loss\"],\n",
        "    \"Speed\": val_results[\"metrics/speed\"],\n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save validation plots\n",
        "model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
        "\n",
        "print(f\"Results saved to {os.path.join(results_dir, model_name)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ql8ugIje01I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the metrics\n",
        "print(\"\\nFinal Metrics:\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric, value in model_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "0q0v0DKG01JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kjb6K6A101JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov5x\n"
      ],
      "metadata": {
        "id": "UsST1R8Q02ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv5x\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov5x.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=12,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=640,\n",
        "    batch=8,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dir, model_name)\n",
        ")\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
        "    \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
        "    \"Precision\": val_results[\"metrics/precision\"],\n",
        "    \"Recall\": val_results[\"metrics/recall\"],\n",
        "    \"F1-Score\": val_results[\"metrics/F1\"],\n",
        "    \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
        "    \"Loss\": val_results[\"metrics/loss\"],\n",
        "    \"Speed\": val_results[\"metrics/speed\"],\n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save validation plots\n",
        "model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
        "\n",
        "print(f\"Results saved to {os.path.join(results_dir, model_name)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GDb4Yxct02ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the metrics\n",
        "print(\"\\nFinal Metrics:\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric, value in model_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "9IyMGdS202ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tQRkszq02ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov6\n",
        "\n"
      ],
      "metadata": {
        "id": "xWnKe1Jv09KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv6\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov6.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=12,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=640,\n",
        "    batch=8,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dir, model_name)\n",
        ")\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
        "    \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
        "    \"Precision\": val_results[\"metrics/precision\"],\n",
        "    \"Recall\": val_results[\"metrics/recall\"],\n",
        "    \"F1-Score\": val_results[\"metrics/F1\"],\n",
        "    \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
        "    \"Loss\": val_results[\"metrics/loss\"],\n",
        "    \"Speed\": val_results[\"metrics/speed\"],\n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save validation plots\n",
        "model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
        "\n",
        "print(f\"Results saved to {os.path.join(results_dir, model_name)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mIaQ8jFx09KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the metrics\n",
        "print(\"\\nFinal Metrics:\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric, value in model_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "U6ErAW7F09KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZjOn_teL09KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov7\n"
      ],
      "metadata": {
        "id": "bTiIzcIF1BDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv7\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov7.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=12,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=640,\n",
        "    batch=8,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dir, model_name)\n",
        ")\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
        "    \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
        "    \"Precision\": val_results[\"metrics/precision\"],\n",
        "    \"Recall\": val_results[\"metrics/recall\"],\n",
        "    \"F1-Score\": val_results[\"metrics/F1\"],\n",
        "    \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
        "    \"Loss\": val_results[\"metrics/loss\"],\n",
        "    \"Speed\": val_results[\"metrics/speed\"],\n",
        "}\n",
        "\n",
        "# Display metrics\n",
        "print(\"\\nMetrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "# Save validation plots\n",
        "model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
        "\n",
        "print(f\"Results saved to {os.path.join(results_dir, model_name)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LdEJdElG1BDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the metrics\n",
        "print(\"\\nFinal Metrics:\")\n",
        "for model_name, model_metrics in metrics.items():\n",
        "    print(f\"\\nModel: {model_name}\")\n",
        "    for metric, value in model_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "ss5oI1n71BDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_4NB1K21BDn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}