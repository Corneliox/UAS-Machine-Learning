{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")  # Path to your YAML file\n",
        "results_dir = os.path.join(drive_base_path, \"results\")     # Directory to save results\n",
        "os.makedirs(results_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PFm9AcKqe8Y",
        "outputId": "dae4a092-75d3-48e9-ea52-271f83be88eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrLsJUPjoy36",
        "outputId": "df8a4f81-9914-4986-c9e0-ed7a08596953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.52)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")\n",
        "results_dir = os.path.join(drive_base_path, \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "'''\n",
        "# Models to train and evaluate\n",
        "models = {\n",
        "    \"YOLOv3\": \"yolov3.pt\",\n",
        "    \"YOLOv4\": \"yolov4.pt\",\n",
        "    \"YOLOv5x\": \"yolov5x.pt\",\n",
        "    \"YOLOv6\": \"yolov6.pt\",\n",
        "    \"YOLOv7\": \"yolov7.pt\",\n",
        "}\n",
        "'''\n",
        "\n",
        "epoch = 12\n",
        "imagesize = 640\n",
        "# batchs = 20 # Maximum For Yolo v3 (14,8 GB Peak)\n",
        "# batchs = 16 # Maximum For Yolo v5x (14,8 GB Peak)"
      ],
      "metadata": {
        "id": "IloKysuTpqwA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov3\n"
      ],
      "metadata": {
        "id": "GFUjvfog0hNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv3\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov3.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Generate unique directory name based on model and current time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "results_dirs = os.path.join(results_dir, f\"{model_name} detection, at {current_time}\")\n",
        "os.makedirs(results_dirs, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=epoch,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=imagesize,\n",
        "    batch=20,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dirs, model_name)\n",
        ")\n",
        "\n",
        "print(f\"Model and results saved to: {results_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQw6mwFrCJo",
        "outputId": "6ef86a23-2f44-4033-a220-eae89551b7f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluating YOLOv3...\n",
            "PRO TIP ðŸ’¡ Replace 'model=yolov3.pt' with new 'model=yolov3u.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov3.pt, data=/content/drive/My Drive/UAS Machine Learning/dataset.yaml, epochs=12, time=None, patience=100, batch=20, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=YOLOv3_detection9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/YOLOv3_detection9\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 1]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     37056  ultralytics.nn.modules.block.Bottleneck      [64, 64]                      \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    295680  ultralytics.nn.modules.block.Bottleneck      [128, 128]                    \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  8   4724736  ultralytics.nn.modules.block.Bottleneck      [256, 256]                    \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  8  18886656  ultralytics.nn.modules.block.Bottleneck      [512, 512]                    \n",
            "  9                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
            " 10                  -1  4  37761024  ultralytics.nn.modules.block.Bottleneck      [1024, 1024]                  \n",
            " 11                  -1  1   9440256  ultralytics.nn.modules.block.Bottleneck      [1024, 1024, False]           \n",
            " 12                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 13                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 14                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 15                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 16                  -2  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 18             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   2950656  ultralytics.nn.modules.block.Bottleneck      [768, 512, False]             \n",
            " 20                  -1  1   2360832  ultralytics.nn.modules.block.Bottleneck      [512, 512, False]             \n",
            " 21                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 22                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
            " 23                  -2  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 25             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 26                  -1  1    738048  ultralytics.nn.modules.block.Bottleneck      [384, 256, False]             \n",
            " 27                  -1  2   1181184  ultralytics.nn.modules.block.Bottleneck      [256, 256, False]             \n",
            " 28        [27, 22, 15]  1   7060444  ultralytics.nn.modules.head.Detect           [4, [256, 512, 1024]]         \n",
            "YOLOv3 summary: 310 layers, 103,695,548 parameters, 103,695,532 gradients, 283.0 GFLOPs\n",
            "\n",
            "Transferred 511/517 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/YOLOv3_detection9', view at http://localhost:6006/\n",
            "Freezing layer 'model.28.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/train/labels.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301/301 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels.cache... 108 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/YOLOv3_detection9/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 84 weight(decay=0.0), 91 weight(decay=0.00046875), 90 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/YOLOv3_detection9\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/12      15.4G      1.992      3.028      2.178         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:23<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597     0.0817     0.0839     0.0418      0.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/12      14.7G      1.899      2.018      1.976         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597   0.000316     0.0232    0.00017   4.65e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/12      15.4G      2.046       2.17      2.182          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:23<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597    0.00271     0.0856     0.0017   0.000643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/12      15.6G      2.048       2.26      2.273          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:21<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.631      0.231      0.114     0.0462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/12      15.4G      2.099      2.226      2.318          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:21<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.219      0.385      0.257     0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/12      15.6G      2.095      1.985      2.237          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:21<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.211      0.349      0.195     0.0658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/12      2.92G      2.076      1.926      2.211          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.288      0.371      0.306      0.126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/12      14.9G      2.013      1.874      2.162          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.389      0.404       0.42      0.178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/12      15.6G      1.947      1.729      2.109          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.668      0.437      0.447      0.177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/12      15.3G      1.933      1.668      2.141          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:21<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.743       0.46      0.489      0.215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/12      15.7G      1.883       1.64      2.077          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.789      0.481      0.539       0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/12      14.8G      1.754      1.458      1.938          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:22<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.786      0.541      0.574      0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "12 epochs completed in 0.148 hours.\n",
            "Optimizer stripped from runs/detect/YOLOv3_detection9/weights/last.pt, 207.7MB\n",
            "Optimizer stripped from runs/detect/YOLOv3_detection9/weights/best.pt, 207.7MB\n",
            "\n",
            "Validating runs/detect/YOLOv3_detection9/weights/best.pt...\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv3 summary (fused): 226 layers, 103,667,324 parameters, 0 gradients, 282.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.786      0.541      0.574      0.273\n",
            "                 Judul        106        107      0.652      0.935      0.875      0.459\n",
            "              Sub-Text         60         63      0.742       0.73      0.791      0.402\n",
            "         Actor/Actress         94        291      0.751      0.488      0.575       0.22\n",
            "               Subject         40        136          1     0.0117     0.0541     0.0128\n",
            "Speed: 0.2ms preprocess, 17.0ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/YOLOv3_detection9\u001b[0m\n",
            "Model and results saved to: /content/drive/My Drive/UAS Machine Learning/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define root output directory\n",
        "root_output_dir = \"/content/drive/My Drive/UAS Machine Learning/Metrics\"\n",
        "os.makedirs(root_output_dir, exist_ok=True)\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Get current time and model name\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format untuk nama folder\n",
        "\n",
        "# Create a unique folder for this validation\n",
        "folder_name = f\"{model_name} metrics at {current_time}\"\n",
        "output_dir = os.path.join(root_output_dir, folder_name)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results.box.map50,         # Mean AP at IoU=0.50\n",
        "    \"AP\": val_results.box.map,            # Mean AP at IoU=0.50:0.95\n",
        "    \"Precision\": val_results.box.mp,      # Mean Precision\n",
        "    \"Recall\": val_results.box.mr,         # Mean Recall\n",
        "    \"F1-Score\": val_results.box.f1,       # F1 score (list per class, optional)\n",
        "}\n",
        "\n",
        "# Save metrics to a file with header\n",
        "metrics_file_path = os.path.join(output_dir, \"metrics.txt\")\n",
        "with open(metrics_file_path, \"w\") as f:\n",
        "    # Write header\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Validation Time: {current_time.replace('_', ' ')}\\n\\n\")  # Replace _ with space for better readability\n",
        "\n",
        "    # Write metrics\n",
        "    for metric, value in metrics.items():\n",
        "        if isinstance(value, (list, np.ndarray)):  # Handle list or numpy array\n",
        "            value_str = \", \".join(f\"{v:.4f}\" for v in value)  # Convert each element to formatted string\n",
        "            line = f\"{metric}: [{value_str}]\"\n",
        "        else:\n",
        "            line = f\"{metric}: {value:.4f}\"\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Display metrics in console\n",
        "print(\"\\nMetrics:\")\n",
        "with open(metrics_file_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(f\"Metrics saved to {metrics_file_path}\")\n",
        "\n",
        "# Save validation plots manually\n",
        "results_dir = val_results.save_dir\n",
        "if os.path.exists(results_dir):\n",
        "    # Move the results directory to the unique folder in Google Drive\n",
        "    destination_dir = os.path.join(output_dir, os.path.basename(results_dir))\n",
        "    os.system(f\"cp -r {results_dir} {destination_dir}\")\n",
        "    print(f\"Validation plots saved to {destination_dir}\")\n",
        "else:\n",
        "    print(\"Validation results directory not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl3JAzzyfRfs",
        "outputId": "2c4bd171-8729-4fbd-bcb2-ed49f228613b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv3 summary (fused): 226 layers, 103,667,324 parameters, 0 gradients, 282.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels.cache... 108 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.786       0.54      0.573      0.272\n",
            "                 Judul        106        107      0.652      0.935      0.874      0.458\n",
            "              Sub-Text         60         63      0.742       0.73      0.791        0.4\n",
            "         Actor/Actress         94        291       0.75      0.485      0.573      0.219\n",
            "               Subject         40        136          1     0.0117     0.0527     0.0127\n",
            "Speed: 0.2ms preprocess, 42.6ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/YOLOv3_detection92\u001b[0m\n",
            "\n",
            "Metrics:\n",
            "Model: YOLOv3\n",
            "Validation Time: 2024-12-20 16-01-55\n",
            "\n",
            "AP50: 0.5726\n",
            "AP: 0.2724\n",
            "Precision: 0.7859\n",
            "Recall: 0.5404\n",
            "F1-Score: [0.7681, 0.7358, 0.5892, 0.0231]\n",
            "\n",
            "Metrics saved to /content/drive/My Drive/UAS Machine Learning/Metrics/YOLOv3 metrics at 2024-12-20_16-01-55/metrics.txt\n",
            "Validation plots saved to /content/drive/My Drive/UAS Machine Learning/Metrics/YOLOv3 metrics at 2024-12-20_16-01-55/YOLOv3_detection92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_dir = \"/content/drive/My Drive/UAS Machine Learning/Logs\"\n",
        "\n",
        "# Step 1: Train and log\n",
        "!mkdir -p logs\n",
        "!python train.py > logs/training_log.txt 2>&1\n",
        "\n",
        "# Step 2: Parse logs and save to Excel\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "log_file_path = \"logs/training_log.txt\"  # Path to the log file\n",
        "output_dir = \"/content/drive/My Drive/UAS Machine Learning/Logs\"  # Save logs to Google Drive\n",
        "\n",
        "with open(log_file_path, \"r\") as file:\n",
        "    training_log = file.read()\n",
        "\n",
        "epoch_pattern = r\"^\\s*(\\d+)/\\d+\\s+(\\d+\\.\\d+G)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\"\n",
        "metrics_pattern = r\"all\\s+(\\d+)\\s+(\\d+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\"\n",
        "\n",
        "epochs = []\n",
        "for epoch_data, metrics_data in zip(\n",
        "    re.findall(epoch_pattern, training_log, re.MULTILINE),\n",
        "    re.findall(metrics_pattern, training_log, re.MULTILINE)\n",
        "):\n",
        "    epoch, gpu_mem, box_loss, cls_loss, dfl_loss = epoch_data\n",
        "    images, instances, p, r, map50, map5095 = metrics_data\n",
        "    epochs.append({\n",
        "        \"Epoch\": int(epoch),\n",
        "        \"GPU_mem\": gpu_mem,\n",
        "        \"Box_Loss\": float(box_loss),\n",
        "        \"Cls_Loss\": float(cls_loss),\n",
        "        \"Dfl_Loss\": float(dfl_loss),\n",
        "        \"Images\": int(images),\n",
        "        \"Instances\": int(instances),\n",
        "        \"P\": float(p),\n",
        "        \"R\": float(r),\n",
        "        \"mAP50\": float(map50),\n",
        "        \"mAP50-95\": float(map5095)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(epochs)\n",
        "\n",
        "time_trained = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "output_file = f\"{output_dir}/Train_{model_name}_at_{time_trained}.xlsx\"\n",
        "\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Training log saved to {output_file}\")"
      ],
      "metadata": {
        "id": "phulBRhVzpXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd0aecd-e80f-4edd-8849-f353b60d9803"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training log saved to /content/drive/My Drive/UAS Machine Learning/Logs/Train_YOLOv3_at_2024-12-20_16-01-58.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo V4 Is Missing Err no Pre trained models"
      ],
      "metadata": {
        "id": "qSk5OWPFoD1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov5x\n"
      ],
      "metadata": {
        "id": "Z6CaYRA8nfGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv5x\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov5x.pt\"    # Pretrained model path for YOLOv5x (update as needed)\n",
        "\n",
        "# Generate unique directory name based on model and current time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "results_dirs = os.path.join(results_dir, f\"{model_name} detection, at {current_time}\")\n",
        "os.makedirs(results_dirs, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=epoch,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=imagesize,\n",
        "    batch=16,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dirs, model_name)\n",
        ")\n",
        "\n",
        "print(f\"Model and results saved to: {results_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3353717c-97c0-445c-abd4-e7e1b503ef22",
        "id": "cWdZ_8xFnfGO"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluating YOLOv5x...\n",
            "PRO TIP ðŸ’¡ Replace 'model=yolov5x.pt' with new 'model=yolov5xu.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5x.pt, data=/content/drive/My Drive/UAS Machine Learning/dataset.yaml, epochs=12, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=YOLOv5x_detection3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/YOLOv5x_detection3\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      8800  ultralytics.nn.modules.conv.Conv             [3, 80, 6, 2, 2]              \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  4    309120  ultralytics.nn.modules.block.C3              [160, 160, 4]                 \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  8   2259200  ultralytics.nn.modules.block.C3              [320, 320, 8]                 \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1 12  13125120  ultralytics.nn.modules.block.C3              [640, 640, 12]                \n",
            "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
            "  8                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4]               \n",
            "  9                  -1  1   4099840  ultralytics.nn.modules.block.SPPF            [1280, 1280, 5]               \n",
            " 10                  -1  1    820480  ultralytics.nn.modules.conv.Conv             [1280, 640, 1, 1]             \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  4   5332480  ultralytics.nn.modules.block.C3              [1280, 640, 4, False]         \n",
            " 14                  -1  1    205440  ultralytics.nn.modules.conv.Conv             [640, 320, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  4   1335040  ultralytics.nn.modules.block.C3              [640, 320, 4, False]          \n",
            " 18                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  4   4922880  ultralytics.nn.modules.block.C3              [640, 640, 4, False]          \n",
            " 21                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  4  19676160  ultralytics.nn.modules.block.C3              [1280, 1280, 4, False]        \n",
            " 24        [17, 20, 23]  1  11025820  ultralytics.nn.modules.head.Detect           [4, [320, 640, 1280]]         \n",
            "YOLOv5x summary: 493 layers, 97,203,260 parameters, 97,203,244 gradients, 246.9 GFLOPs\n",
            "\n",
            "Transferred 817/823 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/YOLOv5x_detection3', view at http://localhost:6006/\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/train/labels.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301/301 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels.cache... 108 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/YOLOv5x_detection3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 135 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/YOLOv5x_detection3\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/12      15.4G      2.023      2.765      1.984        110        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:27<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.165      0.469      0.202     0.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/12      15.3G       1.97      2.061      1.938        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:26<00:00,  1.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597     0.0499       0.46     0.0371     0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/12      15.3G      2.156      2.305      2.203         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:27<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597     0.0499       0.46     0.0371     0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/12      15.2G      2.158      2.256      2.194         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:26<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597   2.15e-05    0.00172   1.09e-05   1.09e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/12      15.3G      2.158      2.275      2.138         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:25<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.608      0.172      0.047     0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/12      15.6G      2.128      2.188      2.138         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:25<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.514      0.336       0.21     0.0695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/12      15.5G      2.058      2.001      2.107         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:26<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.218      0.298      0.154     0.0573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/12      15.6G      2.054      1.947      2.069         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:26<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.317      0.375      0.307      0.115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/12      15.2G      1.997      1.825      1.991         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:25<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597        0.6      0.415      0.334      0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/12      15.6G      1.937      1.742      2.001         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:26<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.656      0.468      0.442      0.189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/12      15.6G      1.914      1.689      1.951         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:25<00:00,  1.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597       0.69      0.491      0.504      0.212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/12      15.6G      1.865       1.64      1.906         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:25<00:00,  1.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597       0.75      0.485      0.526      0.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "12 epochs completed in 0.207 hours.\n",
            "Optimizer stripped from runs/detect/YOLOv5x_detection3/weights/last.pt, 194.9MB\n",
            "Optimizer stripped from runs/detect/YOLOv5x_detection3/weights/best.pt, 194.9MB\n",
            "\n",
            "Validating runs/detect/YOLOv5x_detection3/weights/best.pt...\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv5x summary (fused): 358 layers, 97,156,460 parameters, 0 gradients, 246.0 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597       0.75      0.484      0.526      0.235\n",
            "                 Judul        106        107      0.659      0.813      0.799      0.405\n",
            "              Sub-Text         60         63      0.643      0.619      0.664        0.3\n",
            "         Actor/Actress         94        291      0.701      0.505      0.604      0.224\n",
            "               Subject         40        136          1          0     0.0382     0.0133\n",
            "Speed: 0.2ms preprocess, 20.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/YOLOv5x_detection3\u001b[0m\n",
            "Model and results saved to: /content/drive/My Drive/UAS Machine Learning/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define root output directory\n",
        "root_output_dir = \"/content/drive/My Drive/UAS Machine Learning/Metrics\"\n",
        "os.makedirs(root_output_dir, exist_ok=True)\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Get current time and model name\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format untuk nama folder\n",
        "\n",
        "# Create a unique folder for this validation\n",
        "folder_name = f\"{model_name} metrics at {current_time}\"\n",
        "output_dir = os.path.join(root_output_dir, folder_name)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results.box.map50,         # Mean AP at IoU=0.50\n",
        "    \"AP\": val_results.box.map,            # Mean AP at IoU=0.50:0.95\n",
        "    \"Precision\": val_results.box.mp,      # Mean Precision\n",
        "    \"Recall\": val_results.box.mr,         # Mean Recall\n",
        "    \"F1-Score\": val_results.box.f1,       # F1 score (list per class, optional)\n",
        "}\n",
        "\n",
        "# Save metrics to a file with header\n",
        "metrics_file_path = os.path.join(output_dir, \"metrics.txt\")\n",
        "with open(metrics_file_path, \"w\") as f:\n",
        "    # Write header\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Validation Time: {current_time.replace('_', ' ')}\\n\\n\")  # Replace _ with space for better readability\n",
        "\n",
        "    # Write metrics\n",
        "    for metric, value in metrics.items():\n",
        "        if isinstance(value, (list, np.ndarray)):  # Handle list or numpy array\n",
        "            value_str = \", \".join(f\"{v:.4f}\" for v in value)  # Convert each element to formatted string\n",
        "            line = f\"{metric}: [{value_str}]\"\n",
        "        else:\n",
        "            line = f\"{metric}: {value:.4f}\"\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Display metrics in console\n",
        "print(\"\\nMetrics:\")\n",
        "with open(metrics_file_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(f\"Metrics saved to {metrics_file_path}\")\n",
        "\n",
        "# Save validation plots manually\n",
        "results_dir = val_results.save_dir\n",
        "if os.path.exists(results_dir):\n",
        "    # Move the results directory to the unique folder in Google Drive\n",
        "    destination_dir = os.path.join(output_dir, os.path.basename(results_dir))\n",
        "    os.system(f\"cp -r {results_dir} {destination_dir}\")\n",
        "    print(f\"Validation plots saved to {destination_dir}\")\n",
        "else:\n",
        "    print(\"Validation results directory not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844d025a-9cb3-4edd-b847-9f3b47277f33",
        "id": "211Iv_tcnfGP"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Ultralytics 8.3.52 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels.cache... 108 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.748      0.485      0.525      0.235\n",
            "                 Judul        106        107      0.654      0.813      0.796      0.404\n",
            "              Sub-Text         60         63      0.639      0.619      0.662      0.299\n",
            "         Actor/Actress         94        291        0.7      0.506      0.602      0.224\n",
            "               Subject         40        136          1          0     0.0378     0.0136\n",
            "Speed: 0.3ms preprocess, 43.6ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/YOLOv5x_detection34\u001b[0m\n",
            "\n",
            "Metrics:\n",
            "Model: YOLOv5x\n",
            "Validation Time: 2024-12-20 15-43-56\n",
            "\n",
            "AP50: 0.5247\n",
            "AP: 0.2351\n",
            "Precision: 0.7484\n",
            "Recall: 0.4846\n",
            "F1-Score: [0.7250, 0.6290, 0.5878, 0.0000]\n",
            "\n",
            "Metrics saved to /content/drive/My Drive/UAS Machine Learning/Metrics/YOLOv5x metrics at 2024-12-20_15-43-56/metrics.txt\n",
            "Validation plots saved to /content/drive/My Drive/UAS Machine Learning/Metrics/YOLOv5x metrics at 2024-12-20_15-43-56/YOLOv5x_detection34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_dir = \"/content/drive/My Drive/UAS Machine Learning/Logs\"\n",
        "\n",
        "# Step 1: Train and log\n",
        "!mkdir -p logs\n",
        "!python train.py > logs/training_log.txt 2>&1\n",
        "\n",
        "# Step 2: Parse logs and save to Excel\n",
        "import re\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "log_file_path = \"logs/training_log.txt\"  # Path to the log file\n",
        "output_dir = \"/content/drive/My Drive/UAS Machine Learning/Logs\"  # Save logs to Google Drive\n",
        "\n",
        "with open(log_file_path, \"r\") as file:\n",
        "    training_log = file.read()\n",
        "\n",
        "epoch_pattern = r\"^\\s*(\\d+)/\\d+\\s+(\\d+\\.\\d+G)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\"\n",
        "metrics_pattern = r\"all\\s+(\\d+)\\s+(\\d+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\\s+([\\d.e-]+)\"\n",
        "\n",
        "epochs = []\n",
        "for epoch_data, metrics_data in zip(\n",
        "    re.findall(epoch_pattern, training_log, re.MULTILINE),\n",
        "    re.findall(metrics_pattern, training_log, re.MULTILINE)\n",
        "):\n",
        "    epoch, gpu_mem, box_loss, cls_loss, dfl_loss = epoch_data\n",
        "    images, instances, p, r, map50, map5095 = metrics_data\n",
        "    epochs.append({\n",
        "        \"Epoch\": int(epoch),\n",
        "        \"GPU_mem\": gpu_mem,\n",
        "        \"Box_Loss\": float(box_loss),\n",
        "        \"Cls_Loss\": float(cls_loss),\n",
        "        \"Dfl_Loss\": float(dfl_loss),\n",
        "        \"Images\": int(images),\n",
        "        \"Instances\": int(instances),\n",
        "        \"P\": float(p),\n",
        "        \"R\": float(r),\n",
        "        \"mAP50\": float(map50),\n",
        "        \"mAP50-95\": float(map5095)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(epochs)\n",
        "\n",
        "time_trained = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "output_file = f\"{output_dir}/Train_{model_name}_at_{time_trained}.xlsx\"\n",
        "\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"Training log saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22f9490-2728-4671-c52e-a84bc6d6e73c",
        "id": "6AqakM0dnfGP"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Training log saved to /content/drive/My Drive/UAS Machine Learning/Logs/Train_YOLOv5x_at_2024-12-20_15-27-39.xlsx\n"
          ]
        }
      ]
    }
  ]
}