{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Summary of available models:\n",
        "\n",
        "- yolov8n\n",
        "- yolov8s\n",
        "- yolov8m\n",
        "- yolov8l\n",
        "- yolov8x\n",
        "- yolov5n\n",
        "- yolov5s\n",
        "- yolov5m\n",
        "- yolov5l\n",
        "- yolov5x\n",
        "- yolov3\n",
        "- yolov3-spp\n",
        "- yolov3-tiny"
      ],
      "metadata": {
        "id": "vD_O2xpN_jmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")  # Path to your YAML file\n",
        "results_dir = os.path.join(drive_base_path, \"results\")     # Directory to save results\n",
        "os.makedirs(results_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PFm9AcKqe8Y",
        "outputId": "fa8b6ec7-d435-4e7e-b7ff-abccacbcbbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrLsJUPjoy36",
        "outputId": "75750210-df57-4642-ec01-96672a9c7cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.53-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.53-py3-none-any.whl (902 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m902.2/902.2 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.53 ultralytics-thop-2.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Paths\n",
        "drive_base_path = \"/content/drive/My Drive/UAS Machine Learning\"\n",
        "yaml_path = os.path.join(drive_base_path, \"dataset.yaml\")\n",
        "results_dir = os.path.join(drive_base_path, \"results\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "'''\n",
        "# Models to train and evaluate\n",
        "models = {\n",
        "    \"YOLOv3\": \"yolov3.pt\",\n",
        "    \"YOLOv4\": \"yolov4.pt\",\n",
        "    \"YOLOv5x\": \"yolov5x.pt\",\n",
        "    \"YOLOv6\": \"yolov6.pt\",\n",
        "    \"YOLOv7\": \"yolov7.pt\",\n",
        "}\n",
        "'''\n",
        "\n",
        "epoch = 12\n",
        "imagesize = 640\n",
        "\n",
        "# batchs = 20 # Maximum For Yolo v3 (14,8 GB Peak)\n",
        "# batchs = 16 # Maximum For Yolo v5x (14,8 GB Peak)"
      ],
      "metadata": {
        "id": "IloKysuTpqwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bebda6-5aad-47d1-db8e-37ab96f13368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov3\n"
      ],
      "metadata": {
        "id": "GFUjvfog0hNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics storage\n",
        "metrics = {}\n",
        "\n",
        "# Remmeber to change the batch !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "batch01 = 16\n",
        "\n",
        "# Model to train and evaluate\n",
        "model_name = \"YOLOv3\"       # Change this to the model you want to train (e.g., YOLOv4, YOLOv5x)\n",
        "model_path = \"yolov3.pt\"    # Pretrained model path for YOLOv3 (update as needed)\n",
        "\n",
        "# Generate unique directory name based on model and current time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "results_dirs = os.path.join(results_dir, f\"{current_time}, {model_name} with E/B {epoch}/{batch01}\")\n",
        "os.makedirs(results_dirs, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Train and Evaluate the Model\n",
        "print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "\n",
        "# Train the model\n",
        "model = YOLO(model_path)  # Load pre-trained model\n",
        "model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=epoch,  # Set epochs for quick testing; increase for better results\n",
        "    imgsz=imagesize,\n",
        "    batch=batch01,  # Adjust to fit your GPU memory\n",
        "    name=f\"{model_name}_detection\",\n",
        "    save_dir=os.path.join(results_dirs, model_name)\n",
        ")\n",
        "\n",
        "print(f\"Model and results saved to: {results_dir}\")"
      ],
      "metadata": {
        "id": "nLQw6mwFrCJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea82d085-fe3d-4dcc-a445-2f3ec7c8801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluating YOLOv3...\n",
            "PRO TIP üí° Replace 'model=yolov3.pt' with new 'model=yolov3u.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov3u.pt to 'yolov3u.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198M/198M [00:07<00:00, 29.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.53 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov3.pt, data=/content/drive/My Drive/UAS Machine Learning/dataset.yaml, epochs=12, time=None, patience=100, batch=20, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=YOLOv3_detection, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/YOLOv3_detection\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 1]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     37056  ultralytics.nn.modules.block.Bottleneck      [64, 64]                      \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    295680  ultralytics.nn.modules.block.Bottleneck      [128, 128]                    \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  8   4724736  ultralytics.nn.modules.block.Bottleneck      [256, 256]                    \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  8  18886656  ultralytics.nn.modules.block.Bottleneck      [512, 512]                    \n",
            "  9                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
            " 10                  -1  4  37761024  ultralytics.nn.modules.block.Bottleneck      [1024, 1024]                  \n",
            " 11                  -1  1   9440256  ultralytics.nn.modules.block.Bottleneck      [1024, 1024, False]           \n",
            " 12                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 13                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 14                  -1  1    525312  ultralytics.nn.modules.conv.Conv             [1024, 512, 1, 1]             \n",
            " 15                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 1]             \n",
            " 16                  -2  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 18             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   2950656  ultralytics.nn.modules.block.Bottleneck      [768, 512, False]             \n",
            " 20                  -1  1   2360832  ultralytics.nn.modules.block.Bottleneck      [512, 512, False]             \n",
            " 21                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 22                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 1]              \n",
            " 23                  -2  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 24                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 25             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 26                  -1  1    738048  ultralytics.nn.modules.block.Bottleneck      [384, 256, False]             \n",
            " 27                  -1  2   1181184  ultralytics.nn.modules.block.Bottleneck      [256, 256, False]             \n",
            " 28        [27, 22, 15]  1   7060444  ultralytics.nn.modules.head.Detect           [4, [256, 512, 1024]]         \n",
            "YOLOv3 summary: 310 layers, 103,695,548 parameters, 103,695,532 gradients, 283.0 GFLOPs\n",
            "\n",
            "Transferred 511/517 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/YOLOv3_detection', view at http://localhost:6006/\n",
            "Freezing layer 'model.28.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 232MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/train/labels.cache... 301 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/UAS Machine Learning/val/labels.cache... 108 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108/108 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/YOLOv3_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 84 weight(decay=0.0), 91 weight(decay=0.00046875), 90 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/YOLOv3_detection\u001b[0m\n",
            "Starting training for 12 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/12      15.4G      1.992      3.028      2.178         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:35<00:00,  2.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:11<00:00,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597     0.0817     0.0839     0.0418      0.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/12      15.5G      1.899      2.018      1.976         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:22<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597   0.000316     0.0232    0.00017   4.65e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/12      14.7G      2.046       2.17      2.182          4        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:24<00:00,  1.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597    0.00271     0.0856     0.0017   0.000643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/12        15G      2.048       2.26      2.273          1        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.631      0.231      0.114     0.0462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/12      15.4G      2.099      2.226      2.318          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:24<00:00,  1.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.219      0.385      0.257     0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/12      14.8G      2.095      1.985      2.237          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:24<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.211      0.349      0.195     0.0658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/12      15.3G      2.076      1.926      2.211          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.288      0.371      0.306      0.126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/12      14.9G      2.013      1.874      2.162          6        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.389      0.404       0.42      0.178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/12      14.8G      1.947      1.729      2.109          7        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.668      0.437      0.447      0.177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/12      2.97G      1.933      1.668      2.141          3        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.743       0.46      0.489      0.215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/12      15.6G      1.883       1.64      2.077          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.789      0.481      0.539       0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/12      15.5G      1.754      1.458      1.938          2        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:23<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.786      0.541      0.574      0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "12 epochs completed in 0.132 hours.\n",
            "Optimizer stripped from runs/detect/YOLOv3_detection/weights/last.pt, 207.7MB\n",
            "Optimizer stripped from runs/detect/YOLOv3_detection/weights/best.pt, 207.7MB\n",
            "\n",
            "Validating runs/detect/YOLOv3_detection/weights/best.pt...\n",
            "Ultralytics 8.3.53 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv3 summary (fused): 226 layers, 103,667,324 parameters, 0 gradients, 282.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        108        597      0.786      0.541      0.574      0.273\n",
            "                 Judul        106        107      0.652      0.935      0.875      0.459\n",
            "              Sub-Text         60         63      0.742       0.73      0.791      0.402\n",
            "         Actor/Actress         94        291      0.751      0.488      0.575       0.22\n",
            "               Subject         40        136          1     0.0117     0.0541     0.0128\n",
            "Speed: 0.2ms preprocess, 17.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/YOLOv3_detection\u001b[0m\n",
            "Model and results saved to: /content/drive/My Drive/UAS Machine Learning/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_dir = f\"runs/detect/\"\n",
        "destination_dir = os.path.join(results_dirs, model_name)\n",
        "\n",
        "# Move the directory\n",
        "if os.path.exists(source_dir):\n",
        "    shutil.move(source_dir, destination_dir)\n",
        "    print(f\"Results successfully moved to: {destination_dir}\")\n",
        "else:\n",
        "    print(f\"Source directory not found: {source_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7HEDvXImUum",
        "outputId": "19adebe4-e2f7-4414-9cf6-422da8e84616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results successfully moved to: /content/drive/My Drive/UAS Machine Learning/results/YOLOv3 detection, at 2024-12-22_13-36-44/YOLOv3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define root output directory\n",
        "root_output_dir = \"/content/drive/My Drive/UAS Machine Learning/Metrics\"\n",
        "os.makedirs(root_output_dir, exist_ok=True)\n",
        "\n",
        "# Validate the model\n",
        "val_results = model.val()\n",
        "\n",
        "# Get current time and model name\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format untuk nama folder\n",
        "\n",
        "# Create a unique folder for this validation\n",
        "folder_name = f\"{model_name} metrics at {current_time}\"\n",
        "output_dir = os.path.join(root_output_dir, folder_name)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Collect metrics\n",
        "metrics = {\n",
        "    \"AP50\": val_results.box.map50,         # Mean AP at IoU=0.50\n",
        "    \"AP\": val_results.box.map,            # Mean AP at IoU=0.50:0.95\n",
        "    \"Precision\": val_results.box.mp,      # Mean Precision\n",
        "    \"Recall\": val_results.box.mr,         # Mean Recall\n",
        "    \"F1-Score\": val_results.box.f1,       # F1 score (list per class, optional)\n",
        "}\n",
        "\n",
        "# Save metrics to a file with header\n",
        "metrics_file_path = os.path.join(output_dir, \"metrics.txt\")\n",
        "with open(metrics_file_path, \"w\") as f:\n",
        "    # Write header\n",
        "    f.write(f\"Model: {model_name}\\n\")\n",
        "    f.write(f\"Validation Time: {current_time.replace('_', ' ')}\\n\\n\")  # Replace _ with space for better readability\n",
        "\n",
        "    # Write metrics\n",
        "    for metric, value in metrics.items():\n",
        "        if isinstance(value, (list, np.ndarray)):  # Handle list or numpy array\n",
        "            value_str = \", \".join(f\"{v:.4f}\" for v in value)  # Convert each element to formatted string\n",
        "            line = f\"{metric}: [{value_str}]\"\n",
        "        else:\n",
        "            line = f\"{metric}: {value:.4f}\"\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "# Display metrics in console\n",
        "print(\"\\nMetrics:\")\n",
        "with open(metrics_file_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(f\"Metrics saved to {metrics_file_path}\")\n",
        "\n",
        "# Save validation plots manually\n",
        "results_dir = val_results.save_dir\n",
        "if os.path.exists(results_dir):\n",
        "    # Move the results directory to the unique folder in Google Drive\n",
        "    destination_dir = os.path.join(output_dir, os.path.basename(results_dir))\n",
        "    os.system(f\"cp -r {results_dir} {destination_dir}\")\n",
        "    print(f\"Validation plots saved to {destination_dir}\")\n",
        "else:\n",
        "    print(\"Validation results directory not found.\")\n"
      ],
      "metadata": {
        "id": "nl3JAzzyfRfs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}