{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "yaml_path = \"dataset.yaml\"  \n",
    "results_dir = \"results\"     \n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Model\n",
    "models = {\n",
    "    \"YOLOv3\": \"yolov3.pt\",\n",
    "    \"YOLOv4\": \"yolov4.pt\",\n",
    "    \"YOLOv5x\": \"yolov5x.pt\",\n",
    "    \"YOLOv6\": \"yolov6.pt\",\n",
    "    \"YOLOv7\": \"yolov7.pt\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics store\n",
    "metrics = {}\n",
    "\n",
    "# TEC Metrics for Each Model\n",
    "for model_name, model_path in tqdm(models.items(), desc=\"Processing Models\"):\n",
    "    print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "    \n",
    "    # Train--model\n",
    "    model = YOLO(model_path)  # Load\n",
    "    model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        name=f\"{model_name}_detection\",\n",
    "        save_dir=os.path.join(results_dir, model_name)\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_results = model.val()\n",
    "    \n",
    "    # Metrics\n",
    "    metrics[model_name] = {\n",
    "        \"AP50\": val_results[\"metrics/mAP50\"],  # Average Precision at IoU=0.50\n",
    "        \"AP\": val_results[\"metrics/mAP50-95\"], # Average Precision (IoU=0.50:0.95)\n",
    "        \"Precision\": val_results[\"metrics/precision\"],\n",
    "        \"Recall\": val_results[\"metrics/recall\"],\n",
    "        \"F1-Score\": val_results[\"metrics/F1\"],\n",
    "        \"IoU\": val_results[\"metrics/mIoU\"],  # Mean IoU\n",
    "        \"Loss\": val_results[\"metrics/loss\"],\n",
    "        \"Speed\": val_results[\"metrics/speed\"],\n",
    "    }\n",
    "    \n",
    "    # Save \n",
    "    model.plot_results(save_dir=os.path.join(results_dir, model_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "print(\"\\nFinal Metrics:\")\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric, value in model_metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
